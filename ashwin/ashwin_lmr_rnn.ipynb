{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locomotion Mode Classification Using RNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten\n",
    "from keras.layers import SimpleRNN, LSTM\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.utils import Sequence, to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sit-stand data from file\n",
    "sit_stand_data = loadmat('../Datasets/ashwin_testdata/sit_stand_data_labeled.mat')\n",
    "walk_data = loadmat('../Datasets/ashwin_testdata/walk_data_ashwin.mat')\n",
    "\n",
    "# Some parameters\n",
    "BATCH_SIZE = 32\n",
    "SEQUENCE_LENGTH = 200\n",
    "\n",
    "\n",
    "# Take one 90 seconds of data from the sit-stand and 2 minutes from the walking data for Testing.\n",
    "tmp_x = sit_stand_data['imu_features']\n",
    "tmp_y = sit_stand_data['lm_label']\n",
    "# Sit-Stand test set\n",
    "X_test = tmp_x[tmp_x.shape[0]-8950:, :]\n",
    "Y_test = tmp_y[tmp_x.shape[0]-8950:, :]/100.\n",
    "# Sit-Stand training set\n",
    "X_train = tmp_x[:tmp_x.shape[0]-8950, :]\n",
    "Y_train = tmp_y[:tmp_x.shape[0]-8950, :]\n",
    "\n",
    "tmp_x = walk_data['imu_features']\n",
    "tmp_y = walk_data['lm_label']/300.\n",
    "\n",
    "# Total test set\n",
    "X_test = np.vstack((X_test, tmp_x[tmp_x.shape[0]-12000:, :]))\n",
    "Y_test = np.vstack((Y_test, tmp_y[tmp_y.shape[0]-12000:, :]))\n",
    "\n",
    "# Total training set\n",
    "X_train = np.vstack((X_train, tmp_x[:tmp_x.shape[0]-12000, :]))\n",
    "Y_train = np.vstack((Y_train, tmp_y[:tmp_x.shape[0]-12000, :]))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.title(\"Test Set\")\n",
    "plt.plot(X_test[:, 56:])\n",
    "plt.plot(Y_test*100)\n",
    "plt.ylim([-120, 120])\n",
    "plt.show()\n",
    "\n",
    "# Function to preprocess the data into sequences for the RNN\n",
    "def get_sub_sequences(data_array, y_array, window_size=120, step_size=90, dims=None, seq_out=False, causal=True):\n",
    "    rows = data_array.shape[0]\n",
    "    cols = data_array.shape[1]\n",
    "\n",
    "    if dims == None:\n",
    "        outdims = [i for i in range(cols)]\n",
    "    else:\n",
    "        outdims = dims\n",
    "        \n",
    "    sequences = rows//step_size\n",
    "    out_x = np.zeros((sequences, window_size, len(outdims)))\n",
    "    if seq_out:\n",
    "        out_y = np.zeros((sequences, window_size, y_array.shape[1]))\n",
    "    else:\n",
    "        out_y = np.zeros((sequences, y_array.shape[1]))\n",
    "        \n",
    "    idxs = range(window_size, rows, step_size)    \n",
    "    \n",
    "    for i, j in enumerate(idxs):\n",
    "        out_x[i, :, :] = data_array[j-window_size:j, outdims]\n",
    "        if seq_out:\n",
    "            out_y[i, :, :] = y_array[j-window_size:j, :]\n",
    "        else:\n",
    "            out_y[i, :] = y_array[j, :]\n",
    "    \n",
    "    return out_x, out_y\n",
    "\n",
    "# Make a sequence object from the data \n",
    "class IMUSeq(Sequence):\n",
    "    def __init__(self, xin, yin, length=100, stride=1, batch_size=64):\n",
    "        self.X = xin\n",
    "        self.Y = yin\n",
    "        self.stride=stride\n",
    "        self.length=length\n",
    "    def __len__(self):\n",
    "        idxs = [i for i in range(self.length, self.X.shape[0], self.stride)]\n",
    "        return len(idxs)\n",
    "    def __getitem__(self, idx):\n",
    "        #idxs = [i for i in range(idx*self.length, (idx+1)*self.length)]\n",
    "        x_seq = self.X[idx*self.length:(i+1)*self.length, :]\n",
    "        y_seq = self.Y[idx*self.length:(i+1)*self.length, :]\n",
    "train_ts = IMUSeq(X_train, Y_train, length=SEQUENCE_LENGTH)\n",
    "#train_ts = TimeseriesGenerator(X_train, Y_train, length=SEQUENCE_LENGTH, batch_size=BATCH_SIZE)\n",
    "#print(train_ts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model1 = Sequential()\n",
    "model1.add(SimpleRNN(units=6, activation='softmax', \n",
    "                     return_sequences=True, \n",
    "                     input_shape=(SEQUENCE_LENGTH, X_train.shape[1])))\n",
    "model1.compile(optimizer='rmsprop', \n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "print(\"Model 1 Summary:\")\n",
    "model1.summary()\n",
    "\n",
    "# Train model\n",
    "print(\"Training:\")\n",
    "model1.fit_generator(train_ts, epochs=30, steps_per_epoch=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
